\documentclass[11pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage[vlined, ruled, linesnumbered]{algorithm2e}
\usepackage{amsmath}

\title{Datastructure algorithms}
\author{Jacob Wejendorp}

\begin{document}
\maketitle

\section{Generic Trie}
By first establishing the regular trie methods, a basis is made for evaluating
the modifications required by the other types.

\begin{algorithm}[H]
    \caption{\FuncSty{Insert(}$k$\FuncSty{)}}
    $Node \leftarrow$  root node\;
    \ForEach{char $c$ in $k$}{
        \eIf{$Node$ has child $c$}{
            $Node \leftarrow Node[c]$\;
        }{ %else
            \emph{Create $Node[c]$}\;
            $Node \leftarrow Node[c]$\;
        }
    }
    \emph{Set end of string flag on $Node$}\;
\end{algorithm}
Using this as the basis for the insertion and deletion methods, the trie is
built and searched by reading one character at a time. So just like an
insertion might create a deep path down the trie, a deletion will have to
remove dead ends, upon removing an entry.

A depth-first approach is taken with deletions. The recursive call returns with
a value, determining if changes might be needed at the higher level.

With the nodes having $\alpha$ pointers, the memory overhead for sparse tries
is very big.

As a function of collision odds, each unique subtrie incurs $(\alpha-1) l$
pointers of overhead for a unique substring of length $l$. As such, the total
pointer count is anywhere up to:
\begin{align*}
    M(n) = O(n * (\alpha l - 1))\\
\end{align*}
Which will be used as baseline for comparisons.

The cost of insertion is a function of the chance that a string is unique on
each level. The first insertion has 0 chance of being non-unique, creating a
base-case costing $\alpha$ new pointers in the created subnode.
\[
    T(n) = \left\{ \begin{array}{ll}
                    (\frac{\alpha - 1}{\alpha})^m           & \text{if } n = 1 \\
                    T(n-1) + (\frac{\alpha - 1}{\alpha})^m   & \text{if } n > 1
                   \end{array}
                \right.
\]
For the m'th insertion of an n-length word to the node.



\newpage
\section{Burst trie}
\subsection{Trie algorithms}
Based on the descriptions in [Nash \& Gregg, 2010], the algorithms for search
and insertion are as such:

\begin{algorithm}[H]
    \caption{\FuncSty{Search(}$k$\FuncSty{)}}
    \label{alg:bt_search}

    $Node \leftarrow$  root node\;
    \ForEach{char $c$ in $k$}{
        \eIf{$Node$ has child $c$}{
            $Node \leftarrow Node[c]$\;
        }{ %else
            \eIf{$Node$ has bucket $B[c]$}{
                \emph{Lookup remaining $k$ in $B[c]$}\;
            }{
                \Return{Nothing}\;
            }
        }
    }
\end{algorithm}

where the lookup phase depends on the bucket structure chosen. The original
lookup uses sorted doubly-linked lists. 

\begin{algorithm}[H]
    \caption{\FuncSty{Insert(}$k$\FuncSty{)}}
    \label{alg:bt_insert}

    \SetKwFunction{Burst}{burst}

    $Node \leftarrow$  root node\;
    \tcp{Move down until reaching bucket reference}
    \ForEach{char $c$ in $k$}{
        \If{$Node$ has child $c$}{
            $Node \leftarrow Node[c]$\;
        }
    }
    \tcp{Node either has a bucket at $c$ or one is created}
    \eIf{$Node$ has bucket $B[c]$}{
        \emph{Insert remaining $k$ in $B$}\;
        \If{$B$ is full}{
            $Node[c] \leftarrow \Burst(B)$\;
        }
    }{
        $b \leftarrow $\emph{Create bucket and insert $k$}\;
    }
\end{algorithm}

Deletions are mentioned to be equivalent to insertions, in that removing a key
may cause removal of a bucket, and nodes. The method being equivalent to that
of the basic trie, or the insertion algorithm in reverse.

\begin{algorithm}[H]
    \caption{\FuncSty{Burst(}$b$\FuncSty{)}}
    \label{alg:bt_burst}

    \ForEach{value $k,v$ in $b$}{
        \If{$Node$ has child $c$}{
            $Node \leftarrow Node[c]$\;
        }
    }
\end{algorithm}
\subsection{Bucket structures}
Depending on the chosen bucket structure, insertions, deletions and searches
accomplish different time complexities, and allow different bucket sizes
without becoming inefficient.

\subsubsection{Arrays}
Unsorted arrays make for constant-time insertions, while
requiring linear search time.

A sorted array is the most compressed logarithmic time searchable
representation of the elements. This makes for cache- and time-efficient
searching of the buckets, while increasing the insertion cost to become worst
case linear in the bucket size, with bigger constant factors from
reallocations.

This means that either insertion or searching will be linear in the bucket
size, and therefore define the limit on the desired bucket size.


\subsubsection{Hash tables}
The idea of using hash tables as an intermediate step is dubbed a HAT-trie,
and using bit-wise hashing creates sub-buckets, allowing the buckets
as a whole to become very large without becoming inefficient to access.

This presents the issue of creating an efficient hashing function with
low collision rate. That is, finding the ballance between having $B$
hash containers, which is essentially just another level of nodes, and
the number of collisions resulting in skewed distributions of values amongst
the sub-buckets. 

This concept is further covered in Zobel et al. 2005, which covers cache conscious
hash tables. This means that the buckets can be very large, reducing the number of
nodes created in the trie over all, and with a cache-efficient bucket structure
the overall outcome should be very fast.

\section{Parallelisation}
The primary objective is to avoid data corruption, while allowing several threads
to access the structure at once. For this there are a few schemes with their
respective benefits and gains. Some allow only very little or no parallelism,
others allow conditional parallelism, say for instance having concurrent reads,
exclusive writes, also known as CREW.

\subsection{A locking approach}
A CREW model is easily implemented using a global lock on the structure, which
together with a reference-counter for ongoing searches will allow for the
desired behavior. That is, the searches check the lock state before entering,
and if the structure is not locked, they increase the reference counter,
setting the structure in read-mode.


If it is considered acceptable to have greater overhead from the locks, each
branch could have its own locking, such that only the branch being altered
leaves searches in a waiting state. As such, each level in the trie incurs a
constant overhead, checking the locks before accessing.

The algorithm will unfortunately be serial until the lookup in the bucket
structure, which can, depending on the chosen bucket structure, be
paralellised. This means that $n$ searches can be performed in $O(l+b)$ time,
where $b$ is variable on chosen method for bucket search, but that if
simultanious insertions are performed, the insertion can possibly delay all
other operations.

\subsection{Avoiding locks}
Insertions consist of two phases, the bucket insertion, and the possible
bursting. Bursting can be made dynamically parallel up to a factor of $O(b)$ by
using one thread for each element in the queue, and relying on the recursive
structure of the trie. This means bursting can theoretically be done in
$\omega(1)$ using $b$ processors, but the upper bound depends on the
distribution of the nodes. That is, the only case where the elements will cause
further bursting is if they are identical on the next part of the key, which
has a $\frac{1}{\alpha^b}$ probability.

What if the buckets {\bf grew exponentially} - that would let the bursting be
guaranteed constant, since $b$ elements cannot possibly cause a burst of a
$b*a$ capacity container, with $a > 1$.


I postulate, however, that the structure can be made parallel using a lock-free
bursting scheme, assuming that the bucket container has a series of properties.

If we are to allow searches to proceed unaffected during bursting, the bucket
container needs to be kept active until the nodes have all been inserted into the
newly created node, upon which the pointers are swapped in an atomic operation.
Thus, the bursting thread redistributes the elements in a ghost node, which is
only visible to the trie upon this pointer switch. There might, however be
active searches in the old bucket, which means the bucket needs a reference
counter, which the bursting thread will then have to wait for to become zero.
Then the bucket is removed. The bucket is hereby used as a queue for the
insertion into the new node, and can be searched during this time, if the
elements are copied instead of removed.

The interesting part is when another insertion happens into the same bucket,
which is currently being burst. The bucket structure is assigned an insertion
queue, for use during bursting, since there is no point in making sorted
insertions, when the elements are to be redistributed next.

If the trivial option is chosen, the queue
operates in a FIFO manner during bursting, meaning that the other insertion
happens by simply appending the element to the queues tail in constant time.

Another option could be to allow the container itself to violate its structure
during this phase, to allow atomic insertion.
This requires a buffer to be available in the buckets, for instance by making
sure the bucket is expanded "x" beyond the bucket capacity upon insertion of
the violating element.

The bucket will then need to be flagged, for use with searches, if the order of
the elements is violated on insertion during bursting. A linear search approach
is the forced. The question is whether reusing the bucket is actually the best
solution, or whether a special insertion queue should be used, for instance in
the form of a linked list, which can easily be maintained atomically. Searches
will then have to look at both the linked list and the bucket, but this could
result in $O(\log b + i)$ time instead of $O(b+i)$.

{\bf Note:} If any  of the STL containers are used within the trie, they will
have to be locked on writing, since the STL containers are not thread-safe by
design.

\subsubsection{Linked lists}
A linked list can be maintained using atomic pointer operations, allowing
sorted insertions without relying on locking.
Linked lists are also easily expanded in the way described to be required during
bursting, by appending to the tail of the list, and having the list keep a
pointer to know which of them are in violation, and thereby may require a
full linear lookup, instead of searching only till reaching elements that are
too large.

\subsubsection{Arrays}
It is not possible to avoid locks entirely if the arrays are to be dynamically
expanded during insertions. That is, there is a possibility of a dynamic
reallocation of the array on each insertion.

If the values are sorted as well, almost every insertion will require moving
other elements in the array, and since the array might become invalid in the
mean time, locking is required.

\subsubsection{Hash tables}
If the buckets are of the HAT-trie type, a logical distribution of workers
can be made onto the respective sub buckets, which can then again be burst in
the same way as the aforementioned simple buckets, but will require extra checks
because of the extended structure. The last worker to move all its values will
therefore have to remove all the other buckets, and the hash table, if searches
are to continue using the structure untill the bursting has completed.

\subsection{Parallel algorithms}
On a theoretical level, parallelism is investigated in accordance with Amdahls
law, analyzing each part of the procedure for possible parallelisation.

Following the definition of parallel algorithms, the burst trie algorithms of
page \pageref{alg:bt_insert} are equivalent to the sequential versions, but
with parallelised loops where possible.


where the lookup phase depends on the bucket structure chosen. The original
lookup uses sorted doubly-linked lists. 

\begin{algorithm}[H]
    \caption{\FuncSty{Insert(}$k$\FuncSty{)}}
    \SetKwFunction{Burst}{burst}

    $Node \leftarrow$  root node\;
    \tcp{Move down until reaching bucket reference}
    \ForEach{char $c$ in $k$}{
        \If{$Node$ has child $c$}{
            $Node \leftarrow Node[c]$\;
        }
    }
    \tcp{Node either has a bucket at $c$ or one is created}
    \eIf{$Node$ has bucket $B[c]$}{
        \emph{Insert remaining $k$ in $B$}\;
        \If{$B$ is full}{
            $Node[c] \leftarrow \Burst(B)$\;
        }
    }{
        $b \leftarrow $\emph{Create bucket and insert $k$}\;
    }
\end{algorithm}

\section{Testing}
\begin{itemize}
    \item Randomization with Gnu Scientific Library, controlled distributions
    \item Shakespeare dataset
    \item Valgrind dataset?
\end{itemize}

\end{document}
